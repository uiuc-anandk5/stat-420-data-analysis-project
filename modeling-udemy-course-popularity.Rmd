---
title: "Modeling Udemy Course Popularity"
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(
  scipen = 1,
  digits = 4,
  width = 80,
  fig.align = "center"
)
```

***
*** Delete before submitting

The report should begin with the title of the project.  

Do not include the names of the group members at the outset of the report. 

***

***
*** Delete before submitting

Breakdown of points for analysis report:

Use of Statistical Methodology: 20pts 
- Have you used the appropriate methods for your dataset?  
- Have you applied them correctly? 

Interpretation of Results: 20pts 
- Do you arrive at the correct statistical conclusions from the analyses you perform? 

Discussion of Results: 20pts 
- Do you discuss your analysis results in the context of the data? 

Use of R Programming: 20pts 
- Similar to HW expectation: Does your code perform the desired task?  
- Is your code readable? 


Organization and Presentation: 20pts 
- Similar to HW expectation: Is your report easy to read?  
- Does it use RMarkdown well?  
- Is it written in a manner such that a reader does not already need to be familiar with the data? 

***

## Introduction

***
*** Delete before submitting

The introduction section should relay what you are attempting to accomplish.  

It would include a statement of the business, science, research, or personal interest you have that leads to analyzing the data you’ve chosen.  

It should provide enough background to your work such that a reader would not need to load your data to understand your report.  

Like the simulation project, you can assume the reader is familiar with the course concepts, but not your data.  

Some things to consider: 

- What is this data?  
- Where did it come from?  
- What are the variables?  
- Why is it interesting to you? 
- Why are you creating a model for this data?  
- What is the goal of this model? 

***

The dataset has 3682 records of courses, each with 12 different variables. The most important ones are:

- Course title
- Whether the course is free or paid
- Price of course (in Brazilian Real)
- Number of subscribers
- Number of reviews
- Number of lectures
- Level/difficulty of course
- Course duration (in hours)
- Date the course was published
- Course subject

This dataset was created May 16, 2020 by a data scientist in Brazil. The data can be found here: https://www.kaggle.com/datasets/andrewmvd/udemy-courses?select=udemy_courses.csv

All of our team members are working / have worked in education-related careers, so we really wanted to work on an education-based dataset. Amanda is currently an online course developer for MathWorks on Coursera, so she’s particularly interested in MOOC platform data analysis. Dani does research and analysis at a higher education institution that is planning a large expansion of online offerings.  Anand is a solutions architect at a not-for-profit and has worked on several projects to improve postsecondary education for students by enabling researchers to generate rigorous evidence and help those in the field connect research and practice. 


## Methods

***
*** Delete before submitting

The methods section should contain the bulk of your “work.” This section will contain the bulk of the R code that is used to generate the results. Your R code is not expected to be perfect idiomatic R, but it is expected to be understood by a reader without too much effort. Use RMarkdown and code comments to your advantage to explain your code if needed. 

This section should contain any information about data preparation that is performed to the original data before modelling. Then you will apply methods seen in class, which may include some of the following but are not limited to: 
- Multiple linear regression 
- Dummy variables 
- Interaction 
- Residual diagnostics 
- Outlier diagnostics 
- Transformations 
- Polynomial regression 
- Model selection 

Your task is not to use as many methods as possible. Your task is to use appropriate methods to find a good model that can correctly answer a question about the dataset, and then to communicate your result effectively. Some possible items to be discussed: 
- Description of the original data file including description of all relevant variables. 
- Description of additional data preparation that you performed. 
- Description of the process you chose to follow. 
- Narrative of your step-by-step decision making process throughout the analysis as you adjusted the model and attempted to validate model assumptions. 

***

### Importing the Data and Feature Descriptions

```{r}
library(readr)
udemy = read_csv("udemy_courses.csv", show_col_types = FALSE)
```

Response: num_subscribers
Predictors:
- course_id: Not relevant
- course_title: May be relevant with some text processing
- url: Not relevant
- is_paid: May be relevant
- price: May be relevant
- num_reviews: May be relevant
- num_lectures: May be relevant
- level: May be relevant - As Factor
- content_duration: May be relevant
- published_timestamp: May be relevant
- subject: May be relevant - As Factor

### Data Preprocessing

```{r}
# Removing irrelevant features
udemy = subset(udemy,select=-c(course_id,url,course_title))

# Coercing level and subject to factor variables
udemy$level = as.factor(udemy$level)
udemy$subject = as.factor(udemy$subject)

# Replacing timestamp with days since the course was released
dates = as.Date(substr(udemy$published_timestamp,1,10))
data_retrieval_date = as.Date('2020-05-16')
udemy$days = as.integer(data_retrieval_date - dates)
udemy = subset(udemy,select=-c(published_timestamp))

# Replacing price in BRL with price in USD according to
#  the exchange rate of 0.1708 on 5/16/2020
udemy$price = udemy$price * 0.1708

# Removing course #893 which had no lectures or content duration
udemy = udemy[c(1:892,894:3677),]
```

### Initial Data Exploration

```{r, warning = FALSE}
library(dplyr)
glimpse(udemy)
summary(udemy)
```
#### Initial Exploration of Quantitative Variables
```{r}
plot(x = udemy$price, y = log(udemy$num_subscribers),
     main = "Log Number of Subscribers vs. Price", 
     xlab = "Price (in USD)", ylab = "Log Number of Subscribers")

plot(x = log(udemy$num_reviews), y = log(udemy$num_subscribers),
     main = "Log Number of Subscribers vs. Log Number of Reviews", 
     xlab = "Log Number of Reviews", ylab = "Log Number of Subscribers")

plot(x = log(udemy$num_lectures), y = log(udemy$num_subscribers),
     main = "Log Number of Subscribers vs. Log Number of Lectures", 
     xlab = "Log Number of Lectures", ylab = "Log Number of Subscribers")

plot(x = log(udemy$content_duration), y = log(udemy$num_subscribers),
     main = "Log Number of Subscribers vs. Log Content Duration", 
     xlab = "Log Content Duration (in Hours)", ylab = "Log Number of Subscribers")

plot(x = udemy$days, y = log(udemy$num_subscribers),
     main = "Log Number of Subscribers vs. Days Since Release", 
     xlab = "Number of Days Since Course Release", ylab = "Log Number of Subscribers")
```


```{r warning=FALSE}
#Anand note - Delete chunk prior to submitting.  For insights only.  We should replicate specific analysis manually.
#install.packages("DataExplorer")
#library(DataExplorer)
#DataExplorer::create_report(udemy)
#See report.html
```

### Model Exploration

#### Setting up initial model for exploration
```{r}

udemy_mod = lm(num_subscribers ~ is_paid + price + num_reviews + num_lectures + level + content_duration + subject + days, data = udemy)
summary(udemy_mod)
(n = length(resid(udemy_mod)))
```


```{r}
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (
    1 - hatvalues(model)
  )) ^ 2))
}

#Change traceValue to 1 for output
traceValue = 0

#Backward AIC Search
udemy_mod_back_aic = step(udemy_mod, direction = "backward", trace = traceValue)

#Backward BIC Search
udemy_mod_back_bic = step(udemy_mod,
                          direction = "backward",
                          k = log(n),
                          trace = traceValue)

#Forward AIC Search
udemy_mod_start = lm(num_subscribers ~ 1, data = udemy)
udemy_mod_forward_aic = step(
  udemy_mod_start,
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level +
    content_duration + days + subject,
  direction = "forward",
  trace = traceValue
)

#Forward BIC Search
udemy_mod_forward_bic = step(
  udemy_mod_start,
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level +
    content_duration + days + subject,
  direction = "forward",
  k = log(n),
  trace = traceValue
)

#Stepwise AIC Search
udemy_mod_both_aic = step(
  udemy_mod_start,
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level +
    content_duration + days + subject,
  direction = "both",
  trace = traceValue
)

#Stepwise BIC Search
udemy_mod_both_bic = step(
  udemy_mod_start,
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level +
    content_duration + days + subject,
  direction = "both",
  k = log(n),
  trace = traceValue
)

adj_rsq_mod = summary(udemy_mod)$adj.r.squared
adj_rsq_mod_back_aic = summary(udemy_mod_back_aic)$adj.r.squared
adj_rsq_mod_back_bic = summary(udemy_mod_back_bic)$adj.r.squared
adj_rsq_mod_forward_aic = summary(udemy_mod_forward_aic)$adj.r.squared
adj_rsq_mod_forward_bic = summary(udemy_mod_forward_bic)$adj.r.squared
adj_rsq_mod_both_aic = summary(udemy_mod_both_aic)$adj.r.squared
adj_rsq_mod_both_bic = summary(udemy_mod_both_bic)$adj.r.squared

loocv_adj_rsq_mod = calc_loocv_rmse(udemy_mod)
loocv_rmse_mod_back_aic = calc_loocv_rmse(udemy_mod_back_aic)
loocv_rms_mod_back_bic = calc_loocv_rmse(udemy_mod_back_bic)
loocv_rms_mod_forward_aic = calc_loocv_rmse(udemy_mod_forward_aic)
loocv_rms_mod_forward_bic = calc_loocv_rmse(udemy_mod_forward_bic)
loocv_rms_mod_both_aic = calc_loocv_rmse(udemy_mod_both_aic)
loocv_rms_mod_both_bic = calc_loocv_rmse(udemy_mod_both_bic)

criterion = data.frame(
  'Criterion' = c(
    'additive',
    'Backward Search AIC',
    'Backward Search BIC',
    'Forward Search AIC',
    'Forward Search BIC',
    'Stepwise Search AIC',
    'Stepwise Search BIC'
  ),
  'Adjusted R^2' = c(
    adj_rsq_mod,
    adj_rsq_mod_back_aic,
    adj_rsq_mod_back_bic,
    adj_rsq_mod_forward_aic,
    adj_rsq_mod_forward_bic,
    adj_rsq_mod_both_aic,
    adj_rsq_mod_both_bic
  ),
  'LOOCV_RMSE' = c(
    loocv_adj_rsq_mod,
    loocv_rmse_mod_back_aic,
    loocv_rms_mod_back_bic,
    loocv_rms_mod_forward_aic,
    loocv_rms_mod_forward_bic,
    loocv_rms_mod_both_aic,
    loocv_rms_mod_both_bic
  )
)
library(knitr)
kable(criterion)


```


```{r warning=FALSE}
library(leaps)
library(lmtest)

get_bp_decision = function(model, alpha) {
  decide = unname(bptest(model)$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_sw_decision = function(model, alpha) {
  decide = unname(shapiro.test(resid(model))$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_num_params = function(model) {
  length(coef(model))
}

get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (
    1 - hatvalues(model)
  )) ^ 2))
}

get_adj_r2 = function(model) {
  summary(model)$adj.r.squared
}

n = nrow(udemy)

udemy_model_dredge = lm(
  num_subscribers ~ is_paid + price + num_reviews +
    level + days + subject,
  data = udemy,
  na.action = na.fail
)

library(MuMIn)
combinations = dredge(
  udemy_model_dredge,
  extra = list(
    bptest = function(x)
      if (length(x$coefficients) > 1) {
        bptest(x)$p.value
      },
    
    loocv_rmse = function(x)
      get_loocv_rmse(x),
    
    adj_r2 = function(x)
      get_adj_r2(x)
    
  )
)


#Anand note - Select first result matching criteria (after sorting by bptest and filtering on
#loocv_rmse, adj_r2, and df in combinations dataframe)
#This is not necessarily the best model - just using a placeholder - need to try various transformations
selected_model = lm(
  num_subscribers ~ is_paid + price + num_reviews +
    level + days + subject,
  data = udemy
)

get_loocv_rmse(selected_model)
get_adj_r2(selected_model)
get_bp_decision(selected_model, alpha = 0.01)
get_num_params(selected_model)

```





```{r warning=FALSE}
#Anand note - Temporarily removing course_title - discuss parsing options
library(faraway)
pairs(udemy[,-c(1)], col = "dodgerblue")

#Anand note - Retrieved from https://www.reddit.com/r/Rlanguage/comments/q6let2/problems_with_pairs_corrplot_too_big_illegible/
#Troubleshoot: 'x' must be numeric
#Temporarily Removed course_title, level, published_timestamp, subject
#Note, this code needs to be updated because the ordering of columns might be different after removal of published_timestamp --AW
cor(udemy[,-c(1,7,9,10)]) %>%
  tibble::as_tibble(rownames = "var1") %>%
  tidyr::pivot_longer(!var1, names_to = "var2", values_to = "corr")
```

```{r}
#Anand note: A much better correlation plot allowing for non-numeric factors
#https://stackoverflow.com/questions/52554336/plot-the-equivalent-of-correlation-matrix-for-factors-categorical-data-and-mi
library(ggcorrplot)

#Removed course_title
model.matrix(~0+., data=udemy[-c(1)]) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)

```




*** TBD: Higher order terms

*** TBD: There appear to be outliers - investigate further and remove.

Confirmed via Kaggle notes: https://www.kaggle.com/code/andrewmvd/udemy-courses-getting-started/notebook - "Our plot is being dragged too much due to some outliers. These outliers have either a great amount of reviews (>2000) or great number of subscribers (>10000)."


```{r}
library(lmtest)
bptest(selected_model)

shapiro.test(resid(selected_model))

plot(fitted(selected_model), resid(selected_model), col = "dodgerblue",
     pch = 20, cex = 1.5, xlab = "Fitted", ylab = "Residuals")
abline(h = 0, lty = 2, col = "darkorange", lwd = 2)

#Points of large leverage
sum(hatvalues(selected_model) > 2 * mean(hatvalues(selected_model)))

```

For the Breusch-Pagan test, if we see a small p-value, we reject the null of homoscedasticity. The constant variance assumption is violated.

For the Shaprio-Wilk test, the null hypothesis assumes the data were sampled from a normal distribution, thus a small p-value indicates we believe there is only a small probability the data could have been sampled from a normal distribution.


We notice potential outliers.  Let's find large residuals.


```{r}

#Large residuals
( large_residuals = rstandard(selected_model)[abs(rstandard(selected_model)) > 2] )
length(large_residuals)

```


Let's find influential observations

```{r}

#Influential observations
cooks_distance = cooks.distance(selected_model)
sum(cooks.distance(selected_model) > 4 / length(cooks.distance(selected_model)))

large_influences = cooks.distance(selected_model) > 
  4 / length(cooks.distance(selected_model))
cooks_distance[large_influences]


```

What happens if we remove these observations?

```{r}
#Anand note - This is not necessarily the best model - just using a placeholder -
# Modify this when modifying earlier chunk
selected_model_fixed = lm(
  num_subscribers ~ is_paid + price + num_reviews + 
    level + days + subject, data = udemy,
  subset = cooks_distance <= 4 / length(cooks_distance)
)
coef(selected_model_fixed)

#Original model
par(mfrow = c(2, 2))
plot(selected_model)

#Model after removing influential observations
par(mfrow = c(2, 2))
plot(selected_model_fixed)
```




## Results

***
*** Delete before submitting

The results section should contain numerical or graphical summaries of your results. 

You should report a final model you have chosen.  

There is not necessarily one, singular correct model, but certainly some methods and models are better than others in certain situations. You may use any methods we studied this semester to complete this task, and provide evidence that your final choice of model is a good one.  

Some possible items to be discussed: 

***


## Discussion

***
*** Delete before submitting

The discussion section should contain discussion of your results and should frame your results in the context of the data.  
- How is your final model useful? 

***

## Appendix

***
*** Delete before submitting

The appendix section should contain code and analysis that is used, but that would have otherwise cluttered the report or is not directly related to the choice of model.  

Do not simply dump code in here.  

Only utilize the appendix to supplement the primary focus of the report.  

The appendix should also conclude with the names of the group members. 

***

Group Members: Amanda Wang, Anand Kumar, Dani Richmond

