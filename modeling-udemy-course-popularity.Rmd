---
title: "Modeling Udemy Course Popularity"
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(
  scipen = 1,
  digits = 4,
  width = 80,
  fig.align = "center"
)
```

***
*** Delete before submitting

The report should begin with the title of the project.  

Do not include the names of the group members at the outset of the report. 

***

***
*** Delete before submitting

Breakdown of points for analysis report:

Use of Statistical Methodology: 20pts 
- Have you used the appropriate methods for your dataset?  
- Have you applied them correctly? 

Interpretation of Results: 20pts 
- Do you arrive at the correct statistical conclusions from the analyses you perform? 

Discussion of Results: 20pts 
- Do you discuss your analysis results in the context of the data? 

Use of R Programming: 20pts 
- Similar to HW expectation: Does your code perform the desired task?  
- Is your code readable? 


Organization and Presentation: 20pts 
- Similar to HW expectation: Is your report easy to read?  
- Does it use RMarkdown well?  
- Is it written in a manner such that a reader does not already need to be familiar with the data? 

***

## Introduction

***
*** Delete before submitting

The introduction section should relay what you are attempting to accomplish.  

It would include a statement of the business, science, research, or personal interest you have that leads to analyzing the data you’ve chosen.  

It should provide enough background to your work such that a reader would not need to load your data to understand your report.  

Like the simulation project, you can assume the reader is familiar with the course concepts, but not your data.  

Some things to consider: 

- What is this data?  
- Where did it come from?  
- What are the variables?  
- Why is it interesting to you? 
- Why are you creating a model for this data?  
- What is the goal of this model? 

***

The dataset has 3682 records of courses, each with 12 different variables. The most important ones are:

- Course title
- Whether the course is free or paid
- Price of course
- Number of subscribers
- Number of reviews
- Number of lectures
- Level/difficulty of course
- Course duration (in hours)
- Date the course was published
- Course subject

This dataset was created May 16, 2020 by a data scientist in Brazil. The data can be found here: https://www.kaggle.com/datasets/andrewmvd/udemy-courses?select=udemy_courses.csv

All of our team members are working / have worked in education-related careers, so we really wanted to work on an education-based dataset. Amanda is currently an online course developer for MathWorks on Coursera, so she’s particularly interested in MOOC platform data analysis. Dani does research and analysis at a higher education institution that is planning a large expansion of online offerings.  Anand is a solutions architect at a not-for-profit and has worked on several projects to improve postsecondary education for students by enabling researchers to generate rigorous evidence and help those in the field connect research and practice. 


## Methods

***
*** Delete before submitting

The methods section should contain the bulk of your “work.” This section will contain the bulk of the R code that is used to generate the results. Your R code is not expected to be perfect idiomatic R, but it is expected to be understood by a reader without too much effort. Use RMarkdown and code comments to your advantage to explain your code if needed. 

This section should contain any information about data preparation that is performed to the original data before modelling. Then you will apply methods seen in class, which may include some of the following but are not limited to: 
- Multiple linear regression 
- Dummy variables 
- Interaction 
- Residual diagnostics 
- Outlier diagnostics 
- Transformations 
- Polynomial regression 
- Model selection 

Your task is not to use as many methods as possible. Your task is to use appropriate methods to find a good model that can correctly answer a question about the dataset, and then to communicate your result effectively. Some possible items to be discussed: 
- Description of the original data file including description of all relevant variables. 
- Description of additional data preparation that you performed. 
- Description of the process you chose to follow. 
- Narrative of your step-by-step decision making process throughout the analysis as you adjusted the model and attempted to validate model assumptions. 

***


```{r}
library(readr)
udemy = read_csv("udemy_courses.csv")

```




Response: num_subscribers
Predictors:
- course_id: Not relevant
- course_title: May be relevant
- url: Not relevant
- is_paid: May be relevant
- price: May be relevant
- num_reviews: May be relevant
- num_lectures: May be relevant
- level: May be relevant
- content_duration: May be relevant
- published_timestamp: May be relevant
- subject: May be relevant


```{r}
udemy = subset(udemy,select=-c(course_id,url))
udemy$level = as.factor(udemy$level)
udemy$subject = as.factor(udemy$subject)
```



```{r}
#View(udemy)
library(dplyr)
glimpse(udemy)
summary(udemy)
```



```{r warning=FALSE}
#Anand note - Delete chunk prior to submitting.  For insights only.  We should replicate specific analysis manually.
#install.packages("DataExplorer")
#library(DataExplorer)
#DataExplorer::create_report(udemy)
#See report.html
```


```{r}
#Temporarily removing course_title - discuss parsing options
udemy_mod = lm(num_subscribers ~ .-course_title, data = udemy)
summary(udemy_mod)
(n = length(resid(udemy_mod)))
```


```{r}
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (
    1 - hatvalues(model)
  )) ^ 2))
}

#Change trace = 0 to trace = 1

#Backward AIC Search
udemy_mod_back_aic = step(udemy_mod, direction = "backward", trace = 1)

#Backward BIC Search
udemy_mod_back_bic = step(udemy_mod, direction = "backward", k = log(n), trace = 1)

#Forward AIC Search
udemy_mod_start = lm(num_subscribers ~ 1, data = udemy)
udemy_mod_forward_aic = step(
  udemy_mod_start,
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level + 
    content_duration + published_timestamp + subject,
  direction = "forward", trace = 1
)

#Forward BIC Search
udemy_mod_forward_bic = step(
  udemy_mod_start,
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level + 
    content_duration + published_timestamp + subject,
  direction = "forward", k = log(n), trace = 1
)

#Stepwise AIC Search
udemy_mod_both_aic = step(
  udemy_mod_start, 
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level + 
    content_duration + published_timestamp + subject,
  direction = "both", trace = 1)

#Stepwise BIC Search
udemy_mod_both_bic = step(
  udemy_mod_start, 
  scope = num_subscribers ~ is_paid + price + num_reviews + num_lectures + level + 
    content_duration + published_timestamp + subject,
  direction = "both", k = log(n), trace = 1)

summary(udemy_mod)$adj.r.squared
summary(udemy_mod_back_aic)$adj.r.squared
summary(udemy_mod_back_bic)$adj.r.squared
summary(udemy_mod_forward_aic)$adj.r.squared
summary(udemy_mod_forward_bic)$adj.r.squared
summary(udemy_mod_both_aic)$adj.r.squared
summary(udemy_mod_both_bic)$adj.r.squared

calc_loocv_rmse(udemy_mod)
calc_loocv_rmse(udemy_mod_back_aic)
calc_loocv_rmse(udemy_mod_back_bic)
calc_loocv_rmse(udemy_mod_forward_aic)
calc_loocv_rmse(udemy_mod_forward_bic)
calc_loocv_rmse(udemy_mod_both_aic)
calc_loocv_rmse(udemy_mod_both_bic)

```


```{r}
library(leaps)
library(lmtest)

get_bp_decision = function(model, alpha) {
  decide = unname(bptest(model)$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_sw_decision = function(model, alpha) {
  decide = unname(shapiro.test(resid(model))$p.value < alpha)
  ifelse(decide, "Reject", "Fail to Reject")
}

get_num_params = function(model) {
  length(coef(model))
}

get_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (
    1 - hatvalues(model)
  )) ^ 2))
}

get_adj_r2 = function(model) {
  summary(model)$adj.r.squared
}

n = nrow(udemy)

udemy_model_dredge = lm(
  num_subscribers ~ is_paid + price + num_reviews +
    level + published_timestamp + subject,
  data = udemy,
  na.action = na.fail
)

library(MuMIn)
combinations = dredge(
  udemy_model_dredge,
  extra = list(
    bptest = function(x)
      if (length(x$coefficients) > 1) {
        bptest(x)$p.value
      },
    
    loocv_rmse = function(x)
      get_loocv_rmse(x),
    
    adj_r2 = function(x)
      get_adj_r2(x)
    
  )
)


#Select first result matching criteria (after sorting by bptest and filtering on
#loocv_rmse, adj_r2, and df in combinations dataframe)

#This is not necessarily the best model - just using a placeholder - need to try various transformations
mod_a = lm(
  num_subscribers ~ is_paid + price + num_reviews +
    level + published_timestamp + subject,
  data = udemy
)

get_loocv_rmse(mod_a)
get_adj_r2(mod_a)
get_bp_decision(mod_a, alpha = 0.01)
get_num_params(mod_a)

```





```{r}
#Temporarily removing course_title - discuss parsing options
library(faraway)
pairs(udemy[,-c(1)], col = "dodgerblue")

#Retrieved from https://www.reddit.com/r/Rlanguage/comments/q6let2/problems_with_pairs_corrplot_too_big_illegible/
#Troubleshoot: 'x' must be numeric
#Temporarily Removed course_title, level, published_timestamp, subject
cor(udemy[,-c(1,7,9,10)]) %>%
  tibble::as_tibble(rownames = "var1") %>%
  tidyr::pivot_longer(!var1, names_to = "var2", values_to = "corr")
```


*** To be done: Higher order terms


```{r}
library(lmtest)
bptest(udemy_mod_back_aic)
shapiro.test(resid(udemy_mod_back_aic))


plot(fitted(udemy_mod_back_aic), resid(udemy_mod_back_aic), col = "dodgerblue",
     pch = 20, cex = 1.5, xlab = "Fitted", ylab = "Residuals")
abline(h = 0, lty = 2, col = "darkorange", lwd = 2)




```

For the Breusch-Pagan test, if we see a small p-value, we reject the null of homoscedasticity. The constant variance assumption is violated.

For the Shaprio-Wilk test, the null hypothesis assumes the data were sampled from a normal distribution, thus a small p-value indicates we believe there is only a small probability the data could have been sampled from a normal distribution.







## Results

***
*** Delete before submitting

The results section should contain numerical or graphical summaries of your results. 

You should report a final model you have chosen.  

There is not necessarily one, singular correct model, but certainly some methods and models are better than others in certain situations. You may use any methods we studied this semester to complete this task, and provide evidence that your final choice of model is a good one.  

Some possible items to be discussed: 

***


## Discussion

***
*** Delete before submitting

The discussion section should contain discussion of your results and should frame your results in the context of the data.  
- How is your final model useful? 

***

## Appendix

***
*** Delete before submitting

The appendix section should contain code and analysis that is used, but that would have otherwise cluttered the report or is not directly related to the choice of model.  

Do not simply dump code in here.  

Only utilize the appendix to supplement the primary focus of the report.  

The appendix should also conclude with the names of the group members. 

***

Group Members: Amanda Wang, Anand Kumar, Dani Richmond

